{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow_datasets as tfds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Version:  2.0.0-beta1\n",
      "Eager mode:  True\n",
      "Hub version:  0.5.0\n",
      "GPU is NOT AVAILABLE\n"
     ]
    }
   ],
   "source": [
    "print(\"Version: \", tf.__version__)\n",
    "print(\"Eager mode: \", tf.executing_eagerly())\n",
    "print(\"Hub version: \", hub.__version__)\n",
    "print(\"GPU is\", \"available\" if tf.test.is_gpu_available() else \"NOT AVAILABLE\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**IMDB Dataset**\n",
    "from https://github.com/tensorflow/datasets\n",
    "ref https://github.com/tensorflow/datasets/blob/master/docs/datasets.md#imdb_reviews\n",
    "\n",
    "Large Movie Review Dataset. This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_validation_split = tfds.Split.TRAIN.subsplit([6, 4])\n",
    "\n",
    "(train_data, validation_data), test_data = tfds.load(\n",
    "    name=\"imdb_reviews\", \n",
    "    split=(train_validation_split, tfds.Split.TEST),\n",
    "    as_supervised=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_examples_batch, train_labels_batch = next(iter(train_data.batch(10)))\n",
    "# train_examples_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=446, shape=(2,), dtype=int64, numpy=array([1, 1])>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_labels_batch #0=negative 1=positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "use **pre-trained text embedding model**\n",
    "\n",
    "https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: id=650, shape=(3, 20), dtype=float32, numpy=\n",
       "array([[ 3.9819887 , -4.4838037 ,  5.177359  , -2.3643482 , -3.2938678 ,\n",
       "        -3.5364532 , -2.4786978 ,  2.5525482 ,  6.688532  , -2.3076782 ,\n",
       "        -1.9807833 ,  1.1315885 , -3.0339816 , -0.7604128 , -5.743445  ,\n",
       "         3.4242578 ,  4.790099  , -4.03061   , -5.992149  , -1.7297493 ],\n",
       "       [ 3.4232912 , -4.230874  ,  4.1488533 , -0.29553518, -6.802391  ,\n",
       "        -2.5163853 , -4.4002395 ,  1.905792  ,  4.7512794 , -0.40538004,\n",
       "        -4.3401685 ,  1.0361497 ,  0.9744097 ,  0.71507156, -6.2657013 ,\n",
       "         0.16533905,  4.560262  , -1.3106939 , -3.1121316 , -2.1338716 ],\n",
       "       [ 3.8508697 , -5.003031  ,  4.8700504 , -0.04324996, -5.893603  ,\n",
       "        -5.2983093 , -4.004676  ,  4.1236343 ,  6.267754  ,  0.11632943,\n",
       "        -3.5934832 ,  0.8023905 ,  0.56146765,  0.9192484 , -7.3066816 ,\n",
       "         2.8202746 ,  6.2000837 , -3.5709393 , -4.564525  , -2.305622  ]],\n",
       "      dtype=float32)>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding = \"https://tfhub.dev/google/tf2-preview/gnews-swivel-20dim/1\"\n",
    "hub_layer = hub.KerasLayer(embedding, input_shape=[], dtype=tf.string, trainable=True)\n",
    "hub_layer(train_examples_batch[:3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "keras_layer (KerasLayer)     (None, 20)                400020    \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 16)                336       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 17        \n",
      "=================================================================\n",
      "Total params: 400,373\n",
      "Trainable params: 400,373\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential()\n",
    "model.add(hub_layer)\n",
    "model.add(tf.keras.layers.Dense(16, activation='relu'))\n",
    "model.add(tf.keras.layers.Dense(1, activation='sigmoid'))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/20\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W0712 04:55:53.552644 139714349422336 deprecation.py:323] From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.where in 2.0, which has the same broadcast rule as np.where\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "30/30 [==============================] - 12s 390ms/step - loss: 0.7037 - accuracy: 0.6017 - val_loss: 0.0000e+00 - val_accuracy: 0.0000e+00\n",
      "Epoch 2/20\n",
      "30/30 [==============================] - 10s 328ms/step - loss: 0.6193 - accuracy: 0.6603 - val_loss: 0.5974 - val_accuracy: 0.6844\n",
      "Epoch 3/20\n",
      "30/30 [==============================] - 10s 325ms/step - loss: 0.5852 - accuracy: 0.6978 - val_loss: 0.5714 - val_accuracy: 0.7128\n",
      "Epoch 4/20\n",
      "30/30 [==============================] - 10s 332ms/step - loss: 0.5569 - accuracy: 0.7235 - val_loss: 0.5467 - val_accuracy: 0.7334\n",
      "Epoch 5/20\n",
      "30/30 [==============================] - 10s 325ms/step - loss: 0.5275 - accuracy: 0.7459 - val_loss: 0.5212 - val_accuracy: 0.7545\n",
      "Epoch 6/20\n",
      "30/30 [==============================] - 10s 329ms/step - loss: 0.4963 - accuracy: 0.7729 - val_loss: 0.4941 - val_accuracy: 0.7723\n",
      "Epoch 7/20\n",
      "30/30 [==============================] - 10s 326ms/step - loss: 0.4636 - accuracy: 0.7968 - val_loss: 0.4662 - val_accuracy: 0.7904\n",
      "Epoch 8/20\n",
      "30/30 [==============================] - 10s 330ms/step - loss: 0.4305 - accuracy: 0.8188 - val_loss: 0.4393 - val_accuracy: 0.8063\n",
      "Epoch 9/20\n",
      "30/30 [==============================] - 10s 337ms/step - loss: 0.3983 - accuracy: 0.8361 - val_loss: 0.4143 - val_accuracy: 0.8200\n",
      "Epoch 10/20\n",
      "30/30 [==============================] - 10s 320ms/step - loss: 0.3678 - accuracy: 0.8541 - val_loss: 0.3918 - val_accuracy: 0.8307\n",
      "Epoch 11/20\n",
      "30/30 [==============================] - 10s 318ms/step - loss: 0.3395 - accuracy: 0.8683 - val_loss: 0.3725 - val_accuracy: 0.8416\n",
      "Epoch 12/20\n",
      "30/30 [==============================] - 10s 330ms/step - loss: 0.3135 - accuracy: 0.8793 - val_loss: 0.3557 - val_accuracy: 0.8491\n",
      "Epoch 13/20\n",
      "30/30 [==============================] - 10s 328ms/step - loss: 0.2899 - accuracy: 0.8908 - val_loss: 0.3420 - val_accuracy: 0.8551\n",
      "Epoch 14/20\n",
      "30/30 [==============================] - 10s 329ms/step - loss: 0.2686 - accuracy: 0.8984 - val_loss: 0.3307 - val_accuracy: 0.8602\n",
      "Epoch 15/20\n",
      "30/30 [==============================] - 10s 331ms/step - loss: 0.2493 - accuracy: 0.9079 - val_loss: 0.3216 - val_accuracy: 0.8647\n",
      "Epoch 16/20\n",
      "30/30 [==============================] - 10s 325ms/step - loss: 0.2320 - accuracy: 0.9151 - val_loss: 0.3142 - val_accuracy: 0.8667\n",
      "Epoch 17/20\n",
      "30/30 [==============================] - 10s 328ms/step - loss: 0.2162 - accuracy: 0.9211 - val_loss: 0.3087 - val_accuracy: 0.8694\n",
      "Epoch 18/20\n",
      "30/30 [==============================] - 10s 336ms/step - loss: 0.2016 - accuracy: 0.9280 - val_loss: 0.3049 - val_accuracy: 0.8718\n",
      "Epoch 19/20\n",
      "30/30 [==============================] - 10s 327ms/step - loss: 0.1882 - accuracy: 0.9331 - val_loss: 0.3020 - val_accuracy: 0.8738\n",
      "Epoch 20/20\n",
      "30/30 [==============================] - 10s 335ms/step - loss: 0.1758 - accuracy: 0.9394 - val_loss: 0.3005 - val_accuracy: 0.8747\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(\n",
    "    train_data.shuffle(10000).batch(512),\n",
    "    epochs=20,\n",
    "    validation_data=validation_data.batch(512),\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss: 0.319\n",
      "accuracy: 0.864\n"
     ]
    }
   ],
   "source": [
    "results = model.evaluate(test_data.batch(512), verbose=0)\n",
    "for name, value in zip(model.metrics_names, results):\n",
    "  print(\"%s: %.3f\" % (name, value))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
